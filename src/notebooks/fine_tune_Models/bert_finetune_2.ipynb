{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finetune Bert with train and Eval Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from preprocessor import Preprocessor\n",
    "from data_loading import DataLoader_Data\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/alaaeddinalia/Desktop/Bachelor_Arbeit_2/Rumor_verification/data/raw/English_train.json'\n",
    "data_loader = DataLoader_Data(file_path)\n",
    "\n",
    "# Initialize the preprocessor\n",
    "preprocessor = Preprocessor(language='english', remove_urls=True, remove_special_characters=True\n",
    "                            , remove_stopwords=True , remove_noise_words=True, remove_emojis=True,\n",
    "                            apply_stemming=False, apply_lemmatization=False)\n",
    "\n",
    "# Preprocess the rumors and evidence\n",
    "for item in data_loader.data:\n",
    "    item['rumor'] = preprocessor.preprocess_text(item['rumor'])\n",
    "    for i, evidence_entry in enumerate(item['evidence']):\n",
    "        item['evidence'][i][2] = preprocessor.preprocess_text(evidence_entry[2])\n",
    "    for i, timeline_entry in enumerate(item['timeline']):\n",
    "        item['timeline'][i][2] = preprocessor.preprocess_text(timeline_entry[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pretrain BERT Model for Rumor Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare combined texts and labels for training\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for item in data_loader.data:\n",
    "    evidence_text = \" \".join([e[2] for e in item['evidence']])  # Combine all evidence tweets\n",
    "    combined_text = item['rumor'] + \" \" + evidence_text\n",
    "    texts.append(combined_text)\n",
    "    \n",
    "    # Convert labels to integers\n",
    "    if item['label'] == 'REFUTES':\n",
    "        labels.append(0)\n",
    "    elif item['label'] == 'SUPPORTS':\n",
    "        labels.append(1)\n",
    "    else:  # NOT ENOUGH INFO\n",
    "        labels.append(2)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Preprocessed Data and Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "class RumorDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create the datasets using preprocessed texts\n",
    "train_dataset = RumorDataset(train_texts, train_labels, tokenizer, max_len=512)\n",
    "val_dataset = RumorDataset(val_texts, val_labels, tokenizer, max_len=512)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '“ Watch Qatari suddenly fell inside supermarket Doha suspicions infected Coronan Ministry Public Health confirms circulated social media shopper falling unconscious result infected Corona virus incorrect point shopper suffered sudden fatigue resulted loss balance good health Ministry calls necessity avoiding spreading rumors ensuring accuracy MOPHQatar Ministry Public Health confirms circulated social media shopper falling unconscious result infected Corona virus incorrect would like point shopper suffered sudden fatigue resulting loss balance good health Ministry calls necessity Avoid spreading rumors accurate Ministry Public Health confirms circulated social media shopper falling unconscious result infection Corona virus incorrect would like point shopper suffered sudden fatigue resulting loss balance good health Ministry calls need avoid spreading rumors investigate Precision MOPHQatar Ministry Public Health confirms circulated social media shopper falling unconscious result infected Corona virus incorrect would like point shopper suffered sudden fatigue resulting loss balance good health Ministry calls necessity Avoid spreading rumors accurate MOPHQatar Ministry Public Health confirms circulated social media shopper falling unconscious result infected Corona virus incorrect would like point shopper suffered sudden fatigue resulting loss balance good health Ministry calls necessity Avoid spreading rumors accurate',\n",
       " 'input_ids': tensor([  101,  1523,  3422, 12577,  2072,  3402,  3062,  2503, 17006, 26528,\n",
       "         17817, 10372, 21887,  2078,  3757,  2270,  2740, 23283, 17640,  2591,\n",
       "          2865,  4497,  4842,  4634,  9787,  2765, 10372, 21887,  7865, 16542,\n",
       "          2391,  4497,  4842,  4265,  5573, 16342,  4504,  3279,  5703,  2204,\n",
       "          2740,  3757,  4455, 13185,  9992,  9359, 11256, 12725, 10640,  9587,\n",
       "          8458, 19062,  7559,  3757,  2270,  2740, 23283, 17640,  2591,  2865,\n",
       "          4497,  4842,  4634,  9787,  2765, 10372, 21887,  7865, 16542,  2052,\n",
       "          2066,  2391,  4497,  4842,  4265,  5573, 16342,  4525,  3279,  5703,\n",
       "          2204,  2740,  3757,  4455, 13185,  4468,  9359, 11256,  8321,  3757,\n",
       "          2270,  2740, 23283, 17640,  2591,  2865,  4497,  4842,  4634,  9787,\n",
       "          2765,  8985, 21887,  7865, 16542,  2052,  2066,  2391,  4497,  4842,\n",
       "          4265,  5573, 16342,  4525,  3279,  5703,  2204,  2740,  3757,  4455,\n",
       "          2342,  4468,  9359, 11256,  8556, 11718,  9587,  8458, 19062,  7559,\n",
       "          3757,  2270,  2740, 23283, 17640,  2591,  2865,  4497,  4842,  4634,\n",
       "          9787,  2765, 10372, 21887,  7865, 16542,  2052,  2066,  2391,  4497,\n",
       "          4842,  4265,  5573, 16342,  4525,  3279,  5703,  2204,  2740,  3757,\n",
       "          4455, 13185,  4468,  9359, 11256,  8321,  9587,  8458, 19062,  7559,\n",
       "          3757,  2270,  2740, 23283, 17640,  2591,  2865,  4497,  4842,  4634,\n",
       "          9787,  2765, 10372, 21887,  7865, 16542,  2052,  2066,  2391,  4497,\n",
       "          4842,  4265,  5573, 16342,  4525,  3279,  5703,  2204,  2740,  3757,\n",
       "          4455, 13185,  4468,  9359, 11256,  8321,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/alaaeddinalia/Desktop/bachelor_arbeit_1/Rumor_verification/venv/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.0341541767120361\n",
      "Epoch 2/10, Loss: 0.8659103115399679\n",
      "Epoch 3/10, Loss: 0.7162215560674667\n",
      "Epoch 4/10, Loss: 0.6065972447395325\n",
      "Epoch 5/10, Loss: 0.5441709607839584\n",
      "Epoch 6/10, Loss: 0.46504998455444974\n",
      "Epoch 7/10, Loss: 0.434492955605189\n",
      "Epoch 8/10, Loss: 0.3829097996155421\n",
      "Epoch 9/10, Loss: 0.31461478273073834\n",
      "Epoch 10/10, Loss: 0.25659436732530594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../model_2/rumor_verification_classifier/tokenizer_config.json',\n",
       " '../model_2/rumor_verification_classifier/special_tokens_map.json',\n",
       " '../model_2/rumor_verification_classifier/vocab.txt',\n",
       " '../model_2/rumor_verification_classifier/added_tokens.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "# Initialize the BERT model for sequence classification\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('../model_2/rumor_verification_classifier')\n",
    "tokenizer.save_pretrained('../model_2/rumor_verification_classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alaaeddinalia/Desktop/bachelor_arbeit_1/Rumor_verification/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: AuRED_014, Rumor: “ Urgent Ramallah Ministry Health spokesman Kamal AlShakhra received 2000 doses American “ Moderna ” Corona vaccine batch designated President Abbas Fatah Central Committee VIPs ”\n",
      "Rumor Embedding: (768,), Timeline Embeddings: (75, 768)\n",
      "\n",
      "ID: AuRED_037, Rumor: Macron Sky News visit Mrs Fairouz last night visit Jaj Cedar Reserve realized love large section Lebanese people President Republic Fairouz also told appreciation love President reform project President Republic wants implement also salute President Republic efforts patience\n",
      "Rumor Embedding: (768,), Timeline Embeddings: (1137, 768)\n",
      "\n",
      "ID: AuRED_085, Rumor: Saudi Arabia evacuated 10 students China plane could accommodate 500 passengers evacuate 170 Yemeni students participating 100 warplanes bomb Yemen May God protect Sultanate Oman sending private plane Yemeni students stranded China good neighbor Oman coOfDSIoD5ry\n",
      "Rumor Embedding: (768,), Timeline Embeddings: (139, 768)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from feature_extractor_ import FeatureExtractor\n",
    "\n",
    "# Assuming your FeatureExtractor class is imported or defined in the same notebook\n",
    "# Initialize the feature extractor using BERT\n",
    "extractor = FeatureExtractor(method='bert', bert_model_name='bert-base-uncased', batch_size=16)\n",
    "\n",
    "# Function to extract features for the entire dataset\n",
    "def extract_features(dataset, extractor):\n",
    "    features = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        rumor = item['rumor']\n",
    "        timeline = item['timeline']\n",
    "        \n",
    "        # Extract features for the rumor\n",
    "        rumor_embedding = extractor.fit_transform([rumor])[0]\n",
    "        \n",
    "        # Extract features for the timeline entries\n",
    "        timeline_texts = [entry[2] for entry in timeline]\n",
    "        timeline_embeddings = extractor.transform(timeline_texts)\n",
    "        \n",
    "        features.append({\n",
    "            'id': item['id'],\n",
    "            'rumor': rumor,\n",
    "            'rumor_embedding': rumor_embedding,\n",
    "            'timeline_embeddings': timeline_embeddings,\n",
    "            'timeline': timeline,  # Include the timeline entries here\n",
    "            'true_label': item['label']\n",
    "        })\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Perform feature extraction on the entire dataset\n",
    "features = extract_features(data_loader.data, extractor)\n",
    "\n",
    "# Print a few examples to verify\n",
    "for item in features[:3]:\n",
    "    print(f\"ID: {item['id']}, Rumor: {item['rumor']}\")\n",
    "    print(f\"Rumor Embedding: {item['rumor_embedding'].shape}, Timeline Embeddings: {item['timeline_embeddings'].shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: AuRED_014, Rumor: “ Urgent Ramallah Ministry Health spokesman Kamal AlShakhra received 2000 doses American “ Moderna ” Corona vaccine batch designated President Abbas Fatah Central Committee VIPs ”\n",
      "Selected Evidence: “ Minister Health Dr Mai AlKaila said number convoys sent donation Center reached 5 convoys carrying medical supplies devices medicines Hashemite Charitable Society delivered Ministry Health Palestinian Embassy Amman KSRelief ” Palestinian Minister Health Dr Mai Alkaila 10000 doses Russian Sputnik vaccine arrive today Ministry Health COVID19 SputnikV vaccines Palestine said 730 teams medical health personnel equipped vaccination distributed Ministry Health centers throughout country vaccinate target groups vaccines arrive vaccine palestine COVID19 Minister Health Dr MaiAlkaila inside military hospital Nablus designated treating Covid19 patients various coronavirus treatment centers many governorates today witnessing vaccination campaign health personnel working starting intensive care personnel vaccine Palestine COVID19 Minister Health Dr MayAlkaila today Tuesday campaign received vaccine Hogochaffer Hospital Turmus Aya medical staff working intensive care rooms vaccinated Moderna vaccine modernavaccine palestine COVID19\n",
      "\n",
      "ID: AuRED_037, Rumor: Macron Sky News visit Mrs Fairouz last night visit Jaj Cedar Reserve realized love large section Lebanese people President Republic Fairouz also told appreciation love President reform project President Republic wants implement also salute President Republic efforts patience\n",
      "Selected Evidence: days ago lawyer Majd Harb filed report judiciary Lebanese President Prime Minister Hassan Diab knowledge ammonium nitrate shipment exploded port Judge Ghassan Oueidat today decided keep news preserved according information Beirut new message received one Lebanese stuck Frankfurt Airport Germany talking way embassy Ambassador Mustafa Adeeb dealt case many complaints performance Mustafa Adeeb candidate form new government agreement political forces Beirut short break rescue team rest drinking water focusing plan bulldozer removes possible accumulated rubble great hope living person believed child found great anticipation place throughout country day marks onemonth anniversary Beirut crime Chilean rescue team inspects one demolished buildings Mar Mikhael area suspecting presence people rubble Governor Beirut says Lebanon capabilities expertise equipment disaster management bodies Supreme Authority Disaster Management Governor Beirut speaks like Abu Melhem Mustafa Adeeb candidate form government Lebanese Ambassador Berlin Yesterday refused undergo PCR test made call allowed enter plane without test people expect Mustafa Adeeb\n",
      "\n",
      "ID: AuRED_085, Rumor: Saudi Arabia evacuated 10 students China plane could accommodate 500 passengers evacuate 170 Yemeni students participating 100 warplanes bomb Yemen May God protect Sultanate Oman sending private plane Yemeni students stranded China good neighbor Oman coOfDSIoD5ry\n",
      "Selected Evidence: Prime Minister Dr Maeen Abdulmalik makes phone call Chargé dAffaires Yemeni Embassy China Ahmed Jaber check conditions students Yemeni community stressing government directives President Republic provide coordination Chinese authorities support maintain safety result outbreak Corona virus https tcoUK2xfjBMYk ambassador met Sheikh Abdul Salam AlKhudairi today Undersecretary Ministry Endowments Guidance two sides discussed Corona virus China situation Yemeni expatriates students Sheikh thanked Chinese government efforts combating virus protecting Yemeni citizens expressed hope China defeat virus early coLMgxBmgM7l Prime Minister Dr Maeen Abdulmalik chairs emergency meeting Corona virus necessary measures protect students Yemeni community China directs formation emergency committee headed Deputy Prime Minister Salem AlKhanbashi follow students members community stranded city Wuhan ways evacuate give full health care https tco0SWSLUSq3M YemenPM Prime Minister Dr Maeen Abdulmalik chairs emergency meeting Corona virus necessary measures protect students Yemeni community China directs formation emergency committee headed Deputy Prime Minister Salem AlKhanbashi follow students members community stranded city Wuhan ways evacuate give full health care YemenPM Yemeni Embassy China announces start disbursing financial aid Yemeni students families residing Chinese city Wuhan witnessing spread Corona virus coming days\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Function to retrieve top N evidence based on cosine similarity\n",
    "def retrieve_evidence_from_features(features, top_n=5):\n",
    "    evidence_results = []\n",
    "    \n",
    "    for item in features:\n",
    "        rumor_embedding = item['rumor_embedding']\n",
    "        timeline_embeddings = item['timeline_embeddings']\n",
    "        \n",
    "        # Calculate cosine similarity between rumor and timeline entries\n",
    "        similarities = cosine_similarity([rumor_embedding], timeline_embeddings)[0]\n",
    "        \n",
    "        # Get the top N most similar timeline entries\n",
    "        top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "        selected_evidence_texts = [item['timeline'][i][2] for i in top_indices]\n",
    "        selected_evidence = \" \".join(selected_evidence_texts)\n",
    "        \n",
    "        evidence_results.append({\n",
    "            'id': item['id'],\n",
    "            'rumor': item['rumor'],\n",
    "            'selected_evidence': selected_evidence,\n",
    "            'true_label': item['true_label']\n",
    "        })\n",
    "    \n",
    "    return evidence_results\n",
    "\n",
    "# Perform evidence retrieval using the extracted features\n",
    "evidence_results = retrieve_evidence_from_features(features)\n",
    "\n",
    "# Print a few examples to verify\n",
    "for result in evidence_results[:3]:\n",
    "    print(f\"ID: {result['id']}, Rumor: {result['rumor']}\")\n",
    "    print(f\"Selected Evidence: {result['selected_evidence']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is on the correct device\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Function to classify rumors using the retrieved evidence, including probability predictions\n",
    "def classify_rumors_with_probabilities(evidence_results, model, tokenizer, device):\n",
    "    classification_results = []\n",
    "    label_map = {0: \"REFUTES\", 1: \"SUPPORTS\", 2: \"NOT ENOUGH INFO\"}\n",
    "\n",
    "    for item in evidence_results:\n",
    "        rumor = item['rumor']\n",
    "        combined_text = rumor + \" \" + item['selected_evidence']\n",
    "\n",
    "        # Tokenize and prepare the input for BERT\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            combined_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=256,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "        # Perform classification with the fine-tuned BERT model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "            prediction = torch.argmax(probabilities, dim=1).item()\n",
    "            predicted_prob = probabilities[0].cpu().numpy()  # Convert tensor to numpy array\n",
    "\n",
    "        # Store the classification result\n",
    "        classification_results.append({\n",
    "            'id': item['id'],\n",
    "            'rumor': rumor,\n",
    "            'predicted_label': label_map[prediction],\n",
    "            'true_label': item['true_label'],\n",
    "            'selected_evidence': item['selected_evidence'],\n",
    "            'predicted_probabilities': predicted_prob  # Include predicted probabilities\n",
    "        })\n",
    "\n",
    "    return classification_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: AuRED_014, Rumor: “ Urgent Ramallah Ministry Health spokesman Kamal AlShakhra received 2000 doses American “ Moderna ” Corona vaccine batch designated President Abbas Fatah Central Committee VIPs ”\n",
      "Predicted Label: REFUTES, True Label: REFUTES\n",
      "Selected Evidence: “ Minister Health Dr Mai AlKaila said number convoys sent donation Center reached 5 convoys carrying medical supplies devices medicines Hashemite Charitable Society delivered Ministry Health Palestinian Embassy Amman KSRelief ” Palestinian Minister Health Dr Mai Alkaila 10000 doses Russian Sputnik vaccine arrive today Ministry Health COVID19 SputnikV vaccines Palestine said 730 teams medical health personnel equipped vaccination distributed Ministry Health centers throughout country vaccinate target groups vaccines arrive vaccine palestine COVID19 Minister Health Dr MaiAlkaila inside military hospital Nablus designated treating Covid19 patients various coronavirus treatment centers many governorates today witnessing vaccination campaign health personnel working starting intensive care personnel vaccine Palestine COVID19 Minister Health Dr MayAlkaila today Tuesday campaign received vaccine Hogochaffer Hospital Turmus Aya medical staff working intensive care rooms vaccinated Moderna vaccine modernavaccine palestine COVID19\n",
      "\n",
      "ID: AuRED_037, Rumor: Macron Sky News visit Mrs Fairouz last night visit Jaj Cedar Reserve realized love large section Lebanese people President Republic Fairouz also told appreciation love President reform project President Republic wants implement also salute President Republic efforts patience\n",
      "Predicted Label: REFUTES, True Label: REFUTES\n",
      "Selected Evidence: days ago lawyer Majd Harb filed report judiciary Lebanese President Prime Minister Hassan Diab knowledge ammonium nitrate shipment exploded port Judge Ghassan Oueidat today decided keep news preserved according information Beirut new message received one Lebanese stuck Frankfurt Airport Germany talking way embassy Ambassador Mustafa Adeeb dealt case many complaints performance Mustafa Adeeb candidate form new government agreement political forces Beirut short break rescue team rest drinking water focusing plan bulldozer removes possible accumulated rubble great hope living person believed child found great anticipation place throughout country day marks onemonth anniversary Beirut crime Chilean rescue team inspects one demolished buildings Mar Mikhael area suspecting presence people rubble Governor Beirut says Lebanon capabilities expertise equipment disaster management bodies Supreme Authority Disaster Management Governor Beirut speaks like Abu Melhem Mustafa Adeeb candidate form government Lebanese Ambassador Berlin Yesterday refused undergo PCR test made call allowed enter plane without test people expect Mustafa Adeeb\n",
      "\n",
      "ID: AuRED_085, Rumor: Saudi Arabia evacuated 10 students China plane could accommodate 500 passengers evacuate 170 Yemeni students participating 100 warplanes bomb Yemen May God protect Sultanate Oman sending private plane Yemeni students stranded China good neighbor Oman coOfDSIoD5ry\n",
      "Predicted Label: REFUTES, True Label: REFUTES\n",
      "Selected Evidence: Prime Minister Dr Maeen Abdulmalik makes phone call Chargé dAffaires Yemeni Embassy China Ahmed Jaber check conditions students Yemeni community stressing government directives President Republic provide coordination Chinese authorities support maintain safety result outbreak Corona virus https tcoUK2xfjBMYk ambassador met Sheikh Abdul Salam AlKhudairi today Undersecretary Ministry Endowments Guidance two sides discussed Corona virus China situation Yemeni expatriates students Sheikh thanked Chinese government efforts combating virus protecting Yemeni citizens expressed hope China defeat virus early coLMgxBmgM7l Prime Minister Dr Maeen Abdulmalik chairs emergency meeting Corona virus necessary measures protect students Yemeni community China directs formation emergency committee headed Deputy Prime Minister Salem AlKhanbashi follow students members community stranded city Wuhan ways evacuate give full health care https tco0SWSLUSq3M YemenPM Prime Minister Dr Maeen Abdulmalik chairs emergency meeting Corona virus necessary measures protect students Yemeni community China directs formation emergency committee headed Deputy Prime Minister Salem AlKhanbashi follow students members community stranded city Wuhan ways evacuate give full health care YemenPM Yemeni Embassy China announces start disbursing financial aid Yemeni students families residing Chinese city Wuhan witnessing spread Corona virus coming days\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_dir = '/Users/alaaeddinalia/Desktop/Bachelor_Arbeit_2/Rumor_verification/src/models/rumor_verification_classifier'  # Path where your fine-tuned model is saved\n",
    "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Ensure the model is on the correct device\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Function to classify rumors using the retrieved evidence\n",
    "def classify_rumors(evidence_results, model, tokenizer, device):\n",
    "    classification_results = []\n",
    "    label_map = {0: \"REFUTES\", 1: \"SUPPORTS\", 2: \"NOT ENOUGH INFO\"}\n",
    "\n",
    "    for item in evidence_results:\n",
    "        rumor = item['rumor']\n",
    "        combined_text = rumor + \" \" + item['selected_evidence']\n",
    "\n",
    "        # Tokenize and prepare the input for BERT\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            combined_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=256,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "        # Perform classification with the fine-tuned BERT model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            prediction = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "        # Store the classification result\n",
    "        classification_results.append({\n",
    "            'id': item['id'],\n",
    "            'rumor': rumor,\n",
    "            'predicted_label': label_map[prediction],\n",
    "            'true_label': item['true_label'],\n",
    "            'selected_evidence': item['selected_evidence']\n",
    "        })\n",
    "\n",
    "    return classification_results\n",
    "\n",
    "# Perform classification using the retrieved evidence\n",
    "classification_results = classify_rumors(evidence_results, model, tokenizer, device)\n",
    "\n",
    "# Print a few examples to verify\n",
    "for result in classification_results[:3]:\n",
    "    print(f\"ID: {result['id']}, Rumor: {result['rumor']}\")\n",
    "    print(f\"Predicted Label: {result['predicted_label']}, True Label: {result['true_label']}\")\n",
    "    print(f\"Selected Evidence: {result['selected_evidence']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7046\n",
      "Recall: 0.5104\n",
      "F1 Score: 0.4450\n",
      "All Metrics: {'precision': 0.7046222810111699, 'recall': 0.5104166666666666, 'f1_score': 0.4450373482726424}\n"
     ]
    }
   ],
   "source": [
    "# Convert true and predicted labels to integers\n",
    "label_map = {\"REFUTES\": 0, \"SUPPORTS\": 1, \"NOT ENOUGH INFO\": 2}\n",
    "true_labels_int = [label_map[result['true_label']] for result in classification_results]\n",
    "predicted_labels_int = [label_map[result['predicted_label']] for result in classification_results]\n",
    "\n",
    "# Instantiate the Evaluation class with true and predicted labels\n",
    "evaluator = Evaluation(y_true=true_labels_int, y_pred=predicted_labels_int)\n",
    "\n",
    "# Get individual metrics\n",
    "precision = evaluator.precision()\n",
    "recall = evaluator.recall()\n",
    "f1 = evaluator.f1()\n",
    "\n",
    "# Get all metrics together\n",
    "metrics = evaluator.all_metrics()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print all metrics at once\n",
    "print(\"All Metrics:\", metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
