{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alaaeddinalia/Desktop/bachelor_arbeit /Rumor_verification/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from data_loading import DataLoader_Data\n",
    "from preprocessor import Preprocessor\n",
    "from language_detector import LanguageDetector\n",
    "from feature_extractor_ import FeatureExtractor\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/alaaeddinalia/Desktop/thesis _Rumor_verifiction/Rumor_verification/data/raw/English_train.json'\n",
    "data_loader = DataLoader_Data(file_path)\n",
    "data = data_loader.load_data()\n",
    "\n",
    "from language_detector import LanguageDetector\n",
    "from preprocessor import Preprocessor\n",
    "from data_cleaning import DatasetCleaner\n",
    "\n",
    "# Clean the dataset\n",
    "dataset_cleaner = DatasetCleaner()\n",
    "cleaned_data = dataset_cleaner.remove_irrelevant_rumors(data)\n",
    "\n",
    "\n",
    "# Detect language \n",
    "language_detector = LanguageDetector()\n",
    "detected_language = language_detector.detect_language(cleaned_data[0]['rumor'])\n",
    "\n",
    "\n",
    "preprocessor = Preprocessor(\n",
    "    language=detected_language,\n",
    "    remove_urls=False,\n",
    "    remove_noise_words=False,\n",
    "    remove_special_characters=False,\n",
    "    apply_lemmatization=False\n",
    ")\n",
    "\n",
    "preprocessed_data = []\n",
    "\n",
    "for item in cleaned_data:\n",
    "    \n",
    "    preprocessed_item = item.copy()\n",
    "    \n",
    "    # Preprocess the rumor\n",
    "    preprocessed_item['rumor'] = preprocessor.preprocess_text(item['rumor'])\n",
    "    \n",
    "    # Preprocess each timeline entry's text\n",
    "    for i, timeline_entry in enumerate(item['timeline']):\n",
    "        preprocessed_item['timeline'][i][2] = preprocessor.preprocess_text(timeline_entry[2])\n",
    "    \n",
    "    \n",
    "    preprocessed_data.append(preprocessed_item)\n",
    "\n",
    "\n",
    "from feature_extractor_ import FeatureExtractor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "extractor = FeatureExtractor(method='sbert', sbert_model_name='paraphrase-multilingual-MiniLM-L12-v2', batch_size=16)\n",
    "\n",
    "\n",
    "all_texts = [item['rumor'] for item in preprocessed_data] + \\\n",
    "            [timeline_entry[2] for item in preprocessed_data for timeline_entry in item['timeline']]\n",
    "\n",
    "vectors = extractor.fit_transform(all_texts)\n",
    "\n",
    "index = 0\n",
    "for item in preprocessed_data:\n",
    "    item['rumor_vector'] = vectors[index].tolist()\n",
    "    index += 1\n",
    "    for timeline_entry in item['timeline']:\n",
    "        timeline_entry.append(vectors[index].tolist())\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_evidence(relevant_timelines, evidence):\n",
    "    true_positives = []\n",
    "    false_negatives = []\n",
    "    \n",
    "\n",
    "    retrieved_ids = set([entry['timeline_id'] for entry in relevant_timelines])\n",
    "    evidence_ids = set([entry[1] for entry in evidence])\n",
    "\n",
    "    # True positives: timeline entries in both the retrieved timelines and evidence\n",
    "    true_positives = retrieved_ids.intersection(evidence_ids)\n",
    "\n",
    "    # False negatives: evidence entries that were missed in the retrieved timelines\n",
    "    false_negatives = evidence_ids.difference(retrieved_ids)\n",
    "\n",
    "    return true_positives, false_negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Approach  True Positives (TP)  False Negatives (FN)  Total Evidence\n",
      "0          IQR                  240                    36             276\n",
      "1   Mean Shift                  270                     6             276\n",
      "2  Game Theory                  155                   121             276\n"
     ]
    }
   ],
   "source": [
    "from relevant_timeline_retriever import RelevantTimelineRetriever\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "retriever_iqr = RelevantTimelineRetriever(thresholding_technique='iqr', use_semi_quartile=True)\n",
    "retriever_mean_shift = RelevantTimelineRetriever(thresholding_technique='mean-shift', bandwidth=0.2)\n",
    "retriever_game_theory = RelevantTimelineRetriever(thresholding_technique='game-theory')\n",
    "\n",
    "\n",
    "aggregated_results = {\n",
    "    'IQR': {'True Positives (TP)': 0, 'False Negatives (FN)': 0, 'Total Evidence': 0},\n",
    "    'Mean Shift': {'True Positives (TP)': 0, 'False Negatives (FN)': 0, 'Total Evidence': 0},\n",
    "    'Game Theory': {'True Positives (TP)': 0, 'False Negatives (FN)': 0, 'Total Evidence': 0},\n",
    "}\n",
    "\n",
    "#\n",
    "for idx, rumor_data in enumerate(preprocessed_data):\n",
    "\n",
    "    # Calculate similarities\n",
    "    similarities = retriever_iqr.calculate_similarities([rumor_data]) \n",
    "\n",
    "    # Retrieve relevant timelines using different techniques\n",
    "    relevant_timelines_iqr = retriever_iqr.retrieve_relevant_timelines(similarities, [rumor_data])\n",
    "    relevant_timelines_mean_shift = retriever_mean_shift.retrieve_relevant_timelines(similarities, [rumor_data])\n",
    "    relevant_timelines_game_theory = retriever_game_theory.retrieve_relevant_timelines(similarities, [rumor_data])\n",
    "\n",
    "    # Evidence for the current rumor\n",
    "    evidence_for_rumor = rumor_data['evidence']\n",
    "    total_evidence_for_rumor = len(evidence_for_rumor)\n",
    "\n",
    "    # IQR Technique\n",
    "    tp_iqr, fn_iqr = compare_with_evidence(relevant_timelines_iqr[0]['relevant_timelines'], evidence_for_rumor)\n",
    "    aggregated_results['IQR']['True Positives (TP)'] += len(tp_iqr)\n",
    "    aggregated_results['IQR']['False Negatives (FN)'] += len(fn_iqr)\n",
    "    aggregated_results['IQR']['Total Evidence'] += total_evidence_for_rumor\n",
    "\n",
    "    # Mean Shift Technique\n",
    "    tp_mean_shift, fn_mean_shift = compare_with_evidence(relevant_timelines_mean_shift[0]['relevant_timelines'], evidence_for_rumor)\n",
    "    aggregated_results['Mean Shift']['True Positives (TP)'] += len(tp_mean_shift)\n",
    "    aggregated_results['Mean Shift']['False Negatives (FN)'] += len(fn_mean_shift)\n",
    "    aggregated_results['Mean Shift']['Total Evidence'] += total_evidence_for_rumor\n",
    "\n",
    "    # Game Theory Technique\n",
    "    tp_game_theory, fn_game_theory = compare_with_evidence(relevant_timelines_game_theory[0]['relevant_timelines'], evidence_for_rumor)\n",
    "    aggregated_results['Game Theory']['True Positives (TP)'] += len(tp_game_theory)\n",
    "    aggregated_results['Game Theory']['False Negatives (FN)'] += len(fn_game_theory)\n",
    "    aggregated_results['Game Theory']['Total Evidence'] += total_evidence_for_rumor\n",
    "\n",
    "\n",
    "final_results = pd.DataFrame(aggregated_results).T.reset_index().rename(columns={'index': 'Approach'})\n",
    "\n",
    "# Display table\n",
    "print(final_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cc93f8dff1c92270d493339c16f690d2b8430c71b183d15a508aeaf38ac14d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
