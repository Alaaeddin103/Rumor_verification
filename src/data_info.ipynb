{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: Data Cleaning Summary for Rumors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaning_approach</th>\n",
       "      <th>total_rumors_affected</th>\n",
       "      <th>total_rumors_before_cleaning</th>\n",
       "      <th>total_rumors_after_cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Filtered out irrelevant rumors based on issue ...</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   cleaning_approach  total_rumors_affected  \\\n",
       "0  Filtered out irrelevant rumors based on issue ...                      8   \n",
       "\n",
       "   total_rumors_before_cleaning  total_rumors_after_cleaning  \n",
       "0                            96                           88  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "from data_loading import DataLoader_Data\n",
    "from data_cleaning import DatasetCleaner \n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/alaaeddinalia/Desktop/bachelor_arbeit /Rumor_verification/data/raw/English_train.json' \n",
    "loader = DataLoader_Data(file_path)\n",
    "data = loader.data\n",
    "\n",
    "\n",
    "\n",
    "cleaner = DatasetCleaner()\n",
    "\n",
    "# Run the cleaning process\n",
    "cleaned_data = cleaner.remove_irrelevant_rumors(data)\n",
    "\n",
    "\n",
    "total_rumors_before_cleaning = len(data)  # Total number of rumors before cleaning\n",
    "total_rumors_after_cleaning = 0  # Total number of rumors after cleaning (still have valid tweets)\n",
    "total_rumors_affected = 0  # Number of rumors where tweets were removed\n",
    "\n",
    "# Track cleaning results\n",
    "for rumor in data:\n",
    "    timeline = rumor.get(\"timeline\", [])\n",
    "    total_tweets_before = len(timeline)\n",
    "    cleaned_timeline = [entry for entry in timeline if cleaner.normalize_text(entry[2]) not in cleaner.issue_texts]\n",
    "    total_tweets_after = len(cleaned_timeline)\n",
    "    \n",
    "    # Count rumors that still have valid tweets after cleaning\n",
    "    if total_tweets_after > 0:\n",
    "        total_rumors_after_cleaning += 1\n",
    "    \n",
    "    # Count rumors affected\n",
    "    if total_tweets_before > total_tweets_after:\n",
    "        total_rumors_affected += 1\n",
    "\n",
    "\n",
    "summary_row = {\n",
    "    \"cleaning_approach\": \"Filtered out irrelevant rumors based on issue texts\",\n",
    "    \"total_rumors_affected\": total_rumors_affected,\n",
    "    \"total_rumors_before_cleaning\": total_rumors_before_cleaning,\n",
    "    \"total_rumors_after_cleaning\": total_rumors_after_cleaning\n",
    "}\n",
    "\n",
    "df_summary = pd.DataFrame([summary_row])\n",
    "\n",
    "\n",
    "print(\"Table: Data Cleaning Summary for Rumors\")\n",
    "display(df_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: Data Cleaning Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaning_approach</th>\n",
       "      <th>total_timelines_affected</th>\n",
       "      <th>total_timeline_before_cleaning</th>\n",
       "      <th>total_timeline_after_cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Filtered out irrelevant rumors based on issue ...</td>\n",
       "      <td>3912</td>\n",
       "      <td>21805</td>\n",
       "      <td>17893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   cleaning_approach  \\\n",
       "0  Filtered out irrelevant rumors based on issue ...   \n",
       "\n",
       "   total_timelines_affected  total_timeline_before_cleaning  \\\n",
       "0                      3912                           21805   \n",
       "\n",
       "   total_timeline_after_cleaning  \n",
       "0                          17893  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "from data_loading import DataLoader_Data\n",
    "from data_cleaning import DatasetCleaner \n",
    "\n",
    "# Load the dataset using DataLoader_Data class\n",
    "file_path = '/Users/alaaeddinalia/Desktop/bachelor_arbeit /Rumor_verification/data/raw/English_train.json' \n",
    "loader = DataLoader_Data(file_path)\n",
    "data = loader.data\n",
    "\n",
    "\n",
    "cleaner = DatasetCleaner()\n",
    "\n",
    "# Run the cleaning \n",
    "cleaned_data = cleaner.remove_irrelevant_rumors(data)\n",
    "\n",
    "total_tweets_before_cleaning = 0\n",
    "total_tweets_after_cleaning = 0\n",
    "total_timelines_affected = 0  \n",
    "\n",
    "# Track cleaning results \n",
    "for rumor in data:\n",
    "    timeline = rumor.get(\"timeline\", [])\n",
    "    total_tweets_before = len(timeline)\n",
    "    cleaned_timeline = [entry for entry in timeline if cleaner.normalize_text(entry[2]) not in cleaner.issue_texts]\n",
    "    total_tweets_after = len(cleaned_timeline)\n",
    "    \n",
    "\n",
    "    total_tweets_before_cleaning += total_tweets_before\n",
    "    total_tweets_after_cleaning += total_tweets_after\n",
    "    \n",
    "    # Count the number of tweets affected in the timeline \n",
    "    total_timelines_affected += (total_tweets_before - total_tweets_after)\n",
    "\n",
    "\n",
    "summary_row = {\n",
    "    \"cleaning_approach\": \"Filtered out irrelevant rumors based on issue texts\",\n",
    "    \"total_timelines_affected\": total_timelines_affected,  \n",
    "    \"total_timeline_before_cleaning\": total_tweets_before_cleaning,\n",
    "    \"total_timeline_after_cleaning\": total_tweets_after_cleaning\n",
    "}\n",
    "\n",
    "df_summary = pd.DataFrame([summary_row])\n",
    "\n",
    "\n",
    "print(\"Table: Data Cleaning Summary\")\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: Data Preprocessing Outcome\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach_used</th>\n",
       "      <th>mode_of_effect</th>\n",
       "      <th>tweets_affected_in_timeline</th>\n",
       "      <th>total_tweets_in_timeline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URLs Removed</td>\n",
       "      <td>Removed</td>\n",
       "      <td>13794</td>\n",
       "      <td>17893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noise Words Removed</td>\n",
       "      <td>Removed</td>\n",
       "      <td>17859</td>\n",
       "      <td>17893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Special Characters Removed</td>\n",
       "      <td>Removed</td>\n",
       "      <td>17866</td>\n",
       "      <td>17893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopwords Removed</td>\n",
       "      <td>Removed</td>\n",
       "      <td>17889</td>\n",
       "      <td>17893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                approach_used mode_of_effect  tweets_affected_in_timeline  \\\n",
       "0                URLs Removed        Removed                        13794   \n",
       "1         Noise Words Removed        Removed                        17859   \n",
       "2  Special Characters Removed        Removed                        17866   \n",
       "3           Stopwords Removed        Removed                        17889   \n",
       "\n",
       "   total_tweets_in_timeline  \n",
       "0                     17893  \n",
       "1                     17893  \n",
       "2                     17893  \n",
       "3                     17893  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from data_loading import DataLoader_Data\n",
    "from data_cleaning import DatasetCleaner\n",
    "from preprocessor import Preprocessor \n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/alaaeddinalia/Desktop/bachelor_arbeit /Rumor_verification/data/raw/English_train.json' \n",
    "loader = DataLoader_Data(file_path)\n",
    "data = loader.data\n",
    "\n",
    "\n",
    "cleaner = DatasetCleaner()\n",
    "\n",
    "\n",
    "cleaned_data = cleaner.remove_irrelevant_rumors(data)\n",
    "\n",
    "\n",
    "total_tweets_before_preprocessing = 0\n",
    "preprocessing_results = []\n",
    "\n",
    "\n",
    "preprocessing_steps = [\n",
    "    {\"name\": \"URLs Removed\", \"preprocessor\": Preprocessor(language='english', remove_urls=True)},\n",
    "    {\"name\": \"Noise Words Removed\", \"preprocessor\": Preprocessor(language='english', remove_noise_words=True)},\n",
    "    {\"name\": \"Special Characters Removed\", \"preprocessor\": Preprocessor(language='english', remove_special_characters=True)},\n",
    "    {\"name\": \"Stopwords Removed\", \"preprocessor\": Preprocessor(language='english', remove_stopwords=True)},\n",
    "]\n",
    "\n",
    "# Process each timeline in the dataset\n",
    "for step in preprocessing_steps:\n",
    "    preprocessor = step[\"preprocessor\"]\n",
    "    total_tweets_affected = 0\n",
    "    total_tweets_before = 0\n",
    "\n",
    "    # Track preprocessing for each timeline\n",
    "    for rumor in cleaned_data:\n",
    "        timeline = rumor.get(\"timeline\", [])\n",
    "        total_tweets_before += len(timeline)\n",
    "        \n",
    "      \n",
    "        preprocessed_timeline = [preprocessor.preprocess_text(tweet[2]) for tweet in timeline]\n",
    "        \n",
    "        # Count how many tweets were affected \n",
    "        tweets_affected = sum(1 for original, preprocessed in zip(timeline, preprocessed_timeline) if original[2] != preprocessed)\n",
    "        total_tweets_affected += tweets_affected\n",
    "\n",
    "    \n",
    "    preprocessing_results.append({\n",
    "        \"approach_used\": step[\"name\"],\n",
    "        \"mode_of_effect\": \"Removed\" if \"Removed\" in step[\"name\"] else \"Modified\",\n",
    "        \"tweets_affected_in_timeline\": total_tweets_affected,\n",
    "        \"total_tweets_in_timeline\": total_tweets_before\n",
    "    })\n",
    "\n",
    "\n",
    "df_preprocessing_summary = pd.DataFrame(preprocessing_results)\n",
    "\n",
    "\n",
    "print(\"Table: Data Preprocessing Outcome\")\n",
    "display(df_preprocessing_summary)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cc93f8dff1c92270d493339c16f690d2b8430c71b183d15a508aeaf38ac14d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
